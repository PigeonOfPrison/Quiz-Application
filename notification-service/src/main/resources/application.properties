spring.application.name=notification-service

spring.main.banner-mode=off
server.port=7900

spring.mail.host=smtp.gmail.com
# port would have been 25 if the data was un-encrypted (starttls.enable = false)
spring.mail.port=587
spring.mail.username=pigeon.of.prison@gmail.com
spring.mail.password=HUAhua@452

# smtp.auth -> does this application require the username/passwords to be sent with the mailing request
# smtp.starttls.enable -> does the data sent back and forth needs to be encrypted
spring.mail.properties.mail.smtp.auth=true
spring.mail.properties.mail.smtp.starttls.enable=true

# Configuration for Apache Kafka :4.1.0
# CONSUMER
spring.kafka.bootstrap-servers=localhost:9092
spring.kafka.consumer.group-id=notification-group
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
# Add producer configuration explicitly
spring.kafka.producer.bootstrap-servers=localhost:9092
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
# If you want to send pojo as values (comment out the above line then):
#spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer

## The Code below is for producers
#spring.kafka.bootstrap-servers=localhost:9092
#spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
#spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
## The line below is for when you want to send a pojo as a value (comment out the line above) :
##spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonDeserializer

#Docker command to create a confluentinc kafka container with a volume

#docker run -d --name kafka-vol -p 9092:9092 \
#  -v kafka-data:/var/lib/kafka/data \
#  -e KAFKA_NODE_ID=1 \
#  -e KAFKA_PROCESS_ROLES=broker,controller \
#  -e KAFKA_CONTROLLER_QUORUM_VOTERS=1@localhost:29093 \
#  -e KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER \
#  -e KAFKA_LISTENERS=PLAINTEXT://localhost:9092,CONTROLLER://localhost:29093 \
#  -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092 \
#  -e KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT \
#  -e KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT \
#  -e KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1 \
#  -e KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1 \
#  -e KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1 \
#  -e KAFKA_LOG_RETENTION_HOURS=24 \
#  -e CLUSTER_ID=ciWo7IWazngRchmPES6q5A== \
#  confluentinc/cp-kafka:7.4.0


#Actuator endpoints for health
# Added since they work well with consul service discovery
management.endpoints.web.exposure.include=health
management.endpoint.health.show-details=always

spring.cloud.consul.host=localhost
spring.cloud.consul.port=8500

spring.cloud.consul.discovery.enabled=true
spring.cloud.consul.discovery.register=true
spring.cloud.consul.discovery.prefer-ip-address=true

# Needs spring actuator dependency and the above management properties/ configuration
spring.cloud.consul.discovery.health-check-path=/actuator/health
spring.cloud.consul.discovery.health-check-interval=10s

## config integration (Although we are not using KV yet (consul's other dependency))
#spring.cloud.consul.config.enabled=true
#spring.cloud.consul.config.format=yaml
#spring.cloud.consul.config.prefix=config


# docker command to spin up a consul container
#docker run -d --name=consul -p 8500:8500 -p 8600:8600/udp -v consul-data:/consul/data consul:latest agent -server -bootstrap-expect=1 -ui -client=0.0.0.0